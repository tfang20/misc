from datetime import date, timedelta
import requests
import io
import zipfile
import pandas as pd
import numpy as np

yest = (date.today() - timedelta(1)).strftime("%Y_%m_%d")
userDir = r"\\Ibg\lobdata\TP\FICC\US-CMD-GAS\SDR Swap & Option Analysis\new_sdr_analysis" + "\\" + yest
future_codes = ["","F","G","H","J","K","M","N","Q","U","V","X","Z"]
##### !!!!!!!!!!!!!!!!!!!! THIS LINE NEEDS TO BE CHANGED TO A DIFFERENT ACCOUNT TO WORK; MY ACCOUNT WILL BE SHUT DOWN 8/11/23 @ 3PM
http_proxy = 'http://tfang03:$641FerridayCourt@sccswg.bmogc.net:8080'  #####
############################################################################
proxies={"http":http_proxy,"https":http_proxy}

# download data from dtcc.com, format into main dataframe of relevant data in good format to be used
def download_dtcc():
    # if this link format ever changes this script will fail
    url = "https://kgc0418-tdw-data-0.s3.amazonaws.com/cftc/eod/CFTC_CUMULATIVE_COMMODITIES_" + yest + ".zip"
    request = requests.get(url, proxies = proxies, verify = False)
    zip = zipfile.ZipFile(io.BytesIO(request.content))
    zip.extractall(userDir)

    df = pd.read_csv(userDir + "\CFTC_CUMULATIVE_COMMODITIES_" + yest + ".csv", low_memory = False)
    ### filtering the dataframe
    # filter by new trades only
    df = df[df["Action type"].str.contains("NEWT", na=False)]
    # filter yest only
    df = df[df["Execution Timestamp"].str.contains(yest.replace("_","-"),na=False)]
    # natty only
    df = df[df["Product name"].str.contains("NatGas", na=False)]
    # mbtu only
    df = df[df["Quantity unit of measure-Leg 1"].str.contains("MBTU", na=False)]
    # drop cols that are n/a, replace all n/a with ""
    df = df.dropna(axis = 1, how = "all")
    df = df.replace(np.nan,'', regex =True)
    # only relevant data + relevant formatting
    # df2 holds all the relevant data for the 5 types of trades: nymex swap, nymex option, basis swap, fixed basis swap, fixed basis option
    df2 = df.pop("Event timestamp")
    df2 = pd.concat([df2,df.pop("Underlying asset subtype or underlying contract subtype-Leg 1")], axis = 1)
    df2 = pd.concat([df2,df.pop("Underlying asset subtype or underlying contract subtype-Leg 2")], axis = 1)
    df2 = pd.concat([df2,df.pop("Product name").str[24:].str.replace(":Cash","")], axis = 1)  # only the trade type
    df2 = pd.concat([df2,df.pop("Effective Date").str[:10].apply(pd.to_datetime, format = "%Y-%m-%d").dt.date], axis = 1)  # date format with date only
    # conver to contract code
    df2["Effective Date"] = pd.to_datetime(df2['Effective Date']).dt.strftime('%m').astype(int).apply(lambda x: future_codes[x]) + pd.to_datetime(df2['Effective Date']).dt.strftime('%y')
    df2 = pd.concat([df2,df.pop("Expiration Date").str[:10].apply(pd.to_datetime, format = "%Y-%m-%d").dt.date], axis = 1)  # date format with date only
    # convert to contract code
    df2["Expiration Date"] = pd.to_datetime(df2['Expiration Date']).dt.strftime('%m').astype(int).apply(lambda x: future_codes[x]) + pd.to_datetime(df2['Expiration Date']).dt.strftime('%y')
    # convert to term
    df2["Term"] = df2["Effective Date"] + "/" + df2["Expiration Date"]
    df2 = df2.drop(columns="Effective Date").drop(columns="Expiration Date")
    df2 = pd.concat([df2,df.pop("Maturity date of the underlier").apply(lambda x: pd.to_datetime(x[:10], format = "%Y-%m-%").date() if x else x)], axis = 1)
    df2 = pd.concat([df2,df.pop("Price").apply(lambda x: float(x.replace(",","")) if x != '' else 0)], axis = 1) # get rid of comma, price as float, 0 if empty (options)
    df2 = pd.concat([df2,df.pop("Total notional quantity-Leg 1").apply(lambda x: float(x.replace(",","").replace("+","")) if x != '' else 0)], axis = 1) 
    df2 = pd.concat([df2,df.pop("Total notional quantity-Leg 2").apply(lambda x: float(x.replace(",","").replace("+","")) if x != '' else 0)], axis = 1) 
    df2["Total Notional Lots"] = (df2["Total notional quantity-Leg 1"] + df2["Total notional quantity-Leg 2"]) / 1000
    df2 = df2.drop(columns=["Total notional quantity-Leg 1"]).drop(columns=["Total notional quantity-Leg 2"])
    df2 = pd.concat([df2,df.pop("Strike Price").apply(lambda x: float(x.replace(",","")) if x != "" else 0)], axis = 1)
    df2 = pd.concat([df2,df.pop("Option Type")], axis = 1)
    df2 = pd.concat([df2,df.pop("Option Premium Amount").apply(lambda x: float(x.replace(",","").replace("+","")) if x != "" else 0)], axis = 1)
    df2 = df2.reset_index()
    df2.pop(df2.columns[0])
    # save filtered to csv with df2, which houses all data cleaned
    df2.to_csv(userDir + "\\" + yest + "_DTCC_Data_Cleaned.csv", header = True, index = False, sep=',')
    # save to individual df for later, options & swaps --> later will be refiltered to the 5 types
    df_option = df2[df2["Product name"].isin(["Exotic","Option"])].copy()
    df_swap = df2[df2['Product name'].isin(["Swap"])].copy().drop(columns=["Option Type"])
    df_swap = df_swap.drop(columns="Strike Price").drop(columns="Option Premium Amount").reset_index()
    df_swap.pop(df_swap.columns[0])

    return df_swap, df_option
    
# download data from ice vault, format into main dataframe of relevant data in good format to be used
def download_ice():
    # if the link format, bearer key, or header names ever change this script will fail
    headers = {
    'accept': '*/*',
    'Authorization': 'Bearer eyJhbGciOiJIUzUxMiJ9.eyJpZCI6IjQ4ZmYyNTdjLTcyNzYtNDFlOC04ZmNiLTc3M2M4YWNmNGEzMSJ9.1m8Xffge38E5Oagf_vzeAgAY3j2OyufYktqbPALRqMYzWvHlWRpwZKFbwtLH5BWexV4nPlEMV5OWQ5x7spf7Gw',
    }
    response = requests.get('https://tradevault.ice.com/tvcftc/ticker/webpi/exportTicks?date=' + yest.replace("_","-"),headers = headers, proxies = proxies, verify= False)
    # all values had quotes around them so had to get rid
    df = pd.DataFrame(io.StringIO(response.text.replace('"',"")))
    # set row 1 as headers so can set header names
    df.columns = df.iloc[0]
    df = df["Cleared,Custom basket indicator,Action Type,Event type,Amendment indicator,Event timestamp,Notional amount Leg 1,Notional amount Leg 2,Notional currency Leg 1,Notional currency Leg 2,Notional amount in effect on associated effective date Leg 1,Notional amount in effect on associated effective date Leg 2,Effective Date of the Notional Amount Leg 1,Effective Date of the Notional Amount Leg 2,End Date of Notional Amount Leg 1,End Date of Notional Amount Leg 2,Call Amount Leg 1,Call Amount Leg 2,Call Currency Leg 1,Call Currency Leg 2,Put Amount Leg 1,Put Amount Leg 2,Put Currency Leg 1,Put Currency Leg 2,Notional Quantity Leg 1,Notional Quantity Leg 2,Quantity Frequency Leg 1,Quantity Frequency Leg 2,Quantity Frequency Multiplier Leg 1,Quantity Frequency Multiplier Leg 2,Quantity Unit of Measure Leg 1,Quantity Unit of Measure Leg 2,Total Notional Quantity Leg 1,Total Notional Quantity Leg 2,Package Indicator,Package Transaction Price,Package Transaction Price Currency,Package Transaction Price Notation,Package Transaction Spread,Package Transaction Spread Currency,Package Transaction Spread Notation,Fixed Rate Day Count Convention Leg 1,Fixed Rate Day Count Convention Leg 2,Floating Rate Day Count Convention Leg 1,Floating Rate Day Count Convention Leg 2,Floating Rate Reset Frequency Period Leg 1,Floating Rate Reset Frequency Period Leg 2,Floating Rate Reset Frequency Period Multiplier Leg 1,Floating Rate Reset Frequency Period Multiplier Leg 2,Other Payment Type,Other Payment Amount,Other Payment Currency,Fixed Rate Payment Frequency Period Leg 1,Fixed Rate Payment Frequency Period Leg 2,Floating Rate Payment Frequency Period Leg 1,Floating Rate Payment Frequency Period Leg 2,Fixed Rate Payment Frequency Period Multiplier Leg 1,Fixed Rate Payment Frequency Period Multiplier Leg 2,Floating Rate Payment Frequency Period Multiplier Leg 1,Floating Rate Payment Frequency Period Multiplier Leg 2,Exchange Rate,Exchange Rate Basis,Fixed Rate Leg 1,Fixed Rate Leg 2,Post Price Swap Indicator,Price,Price Currency,Price Notation,Price unit of Measure,Spread Leg 1,Spread Leg 2,Spread Currency Leg 1,Spread Currency Leg 2,Spread Notation Leg 1,Spread Notation Leg 2,Strike Price,Strike Price Currency / Currency Pair,Strike Price Notation,Option Premium Amount,Option Premium Currency,First Exercise Date,Index Factor,Embedded Option Type,Settlement Currency Leg 1,Settlement Currency Leg 2,Settlement Location Leg 1,Settlement Location Leg 2,Non Standardized Term Indicator,Block Trade Election Indicator,Effective date,Expiration date,Execution timestamp,Platform Identifier,Prime brokerage transaction indicator,Asset Class,Delivery Type,Instrument Type,Standard Contract Specification,Underlier ID Leg 1,Underlier ID Leg 2,Underlier ID Source Leg 1,Underlier ID Source Leg 2,Underlying Asset or Underlying Contract Type Leg 1,Underlying Asset or Underlying Contract Type Leg 2,Underlying Asset Subtype or Underlying Contract Subtype Leg 1,Underlying Asset Subtype or Underlying Contract Subtype Leg 2,Underlying Credit Index Series,Underlying Credit Index Version,Product Name,Physical Delivery Region Leg 1,Physical Delivery Region Leg 2,Pricing Index Region Leg 1,Pricing Index Region Leg 2,Physical Delivery Location Leg 1,Physical Delivery Location Leg 2,Maturity Date of the Underlier,Large Notional Off-Facility Swap Election Indicator,Dissemination Identifier,Original Dissemination Identifier,Dissemination Timestamp\n"].str.split(",", expand=True)
    df.columns = df.iloc[0]
    # save unfiltered to csv
    df.to_csv(userDir + "\\" + yest + "_ICE_Data.csv", header = False, index = False, sep=',')
    ### filtering the dataframe
    # filter by new trades only
    df = df[df["Action Type"].str.contains('NEWT', na=False)]
    # filter yest only
    df = df[df["Event timestamp"].str.contains(yest.replace("_","-"),na=False)]
    # MBTU only
    df = df[df["Quantity Unit of Measure Leg 1"].str.contains("MBTU", na=False)]
    # omit masked/only natty
    # df = df[df["Underlier ID Leg 1"].str.contains("NAT",na=False)]
    # drop cols thatre all empty
    df = df.dropna(axis=1,how='all')
    # df2 holds all the relevant data for the 5 types of trades: nymex swap, nymex option, basis swap, fixed basis swap, fixed basis option
    df2 = df.pop("Event timestamp")
    df2 = pd.concat([df2,df.pop("Underlier ID Leg 1")], axis = 1)
    df2 = pd.concat([df2,df.pop("Product Name")], axis = 1)

    ###########################################
    # not using these cols anymore, irrelevant
    # df2 = pd.concat([df2,df.pop("Delivery Type")], axis = 1)
    # df2 = pd.concat([df2,df.pop("Instrument Type")], axis = 1)
    # df2["Trade Type"] = df2["Delivery Type"] + df2["Instrument Type"]
    # df2 = df2.drop(columns=['Delivery Type'])
    # df2 = df2.drop(columns=['Instrument Type'])
    ###########################################

    # convert to date and only have relevant start date
    df2 = pd.concat([df2,df.pop("Effective date").str[:10].apply(pd.to_datetime, format = "%Y-%m-%d").dt.date], axis = 1)
    # convert to contract code
    df2["Effective date"] = pd.to_datetime(df2['Effective date']).dt.strftime('%m').astype(int).apply(lambda x: future_codes[x]) + pd.to_datetime(df2['Effective date']).dt.strftime('%y')
    # get relevant date, convert to datetime
    df2 = pd.concat([df2,df.pop("Expiration date").str[-10:].apply(pd.to_datetime, format = "%Y-%m-%d").dt.date], axis = 1)
    # convert to contract code
    df2["Expiration date"] = pd.to_datetime(df2['Expiration date']).dt.strftime('%m').astype(int).apply(lambda x: future_codes[x]) + pd.to_datetime(df2['Expiration date']).dt.strftime('%y')
    # convert to term
    df2["Term"] = df2["Effective date"] + "/" + df2["Expiration date"]
    df2 = df2.drop(columns="Effective date").drop(columns="Expiration date")
    # convert prices to readable format: delimit by "|", calc average to get price of trade
        # takes the cell in price, calcs average, returns; gives 0 when no value (e.g. when option so no price data) --> should be function bc repeated but oh well
        ### this should really be day weighted average instead of simple average, so a few cents off; assumes trader knows the prev trading range
    df2 = pd.concat([df2,df.pop("Price")], axis = 1)
    for index, row in df2.iterrows():
        prices = row['Price'].split("|")
        prices = [float(price) if price != "" else 0 for price in prices]
        average = sum(prices) / len(prices)
        df2.at[index,'Price'] = average
    # convert to number format, combine into one column
    df2 = pd.concat([df2,df.pop("Total Notional Quantity Leg 1").apply(lambda x: float(x.replace(",","")) if x != '' else 0)], axis = 1)
    df2 = pd.concat([df2,df.pop("Total Notional Quantity Leg 2").apply(lambda x: float(x.replace(",","")) if x != '' else 0)], axis = 1)
    df2["Total Notional Lots"] = (df2["Total Notional Quantity Leg 1"] + df2["Total Notional Quantity Leg 2"]) / 1000
    df2 = df2.drop(columns=["Total Notional Quantity Leg 1"]).drop(columns=["Total Notional Quantity Leg 2"])
    # calc avg, same way as price; should also be weighted but assumes trader knows range so simple avg
    df2 = pd.concat([df2,df.pop("Strike Price")], axis = 1)
    for index, row in df2.iterrows():
        prices = row['Strike Price'].split("|")
        prices = [float(price) if price != "" else 0 for price in prices]
        average = sum(prices) / len(prices)
        df2.at[index,'Strike Price'] = average
    # convert to number format, combine into one column; 0 if empty cell
    df2 = pd.concat([df2,df.pop("Call Amount Leg 1").apply(lambda x: float(x.replace(",","")) if x != '' else 0)], axis = 1)
    df2 = pd.concat([df2,df.pop("Call Amount Leg 2").apply(lambda x: float(x.replace(",","")) if x != '' else 0)], axis = 1)
    df2['Total Call Amount'] = df2["Call Amount Leg 1"] + df2["Call Amount Leg 2"]
    df2 = df2.drop(columns=['Call Amount Leg 1']).drop(columns=["Call Amount Leg 2"])
    df2 = pd.concat([df2,df.pop("Put Amount Leg 1").apply(lambda x: float(x.replace(",","")) if x != '' else 0)], axis = 1)
    df2 = pd.concat([df2,df.pop("Put Amount Leg 2").apply(lambda x: float(x.replace(",","")) if x != '' else 0)], axis = 1)
    df2['Total Put Amount'] = df2["Put Amount Leg 1"] + df2["Put Amount Leg 2"]
    df2 = df2.drop(columns=['Put Amount Leg 1']).drop(columns=["Put Amount Leg 2"])
    df2 = pd.concat([df2,df.pop("Option Premium Amount")], axis = 1)
    for index, row in df2.iterrows():
        prices = row['Option Premium Amount'].split("|")
        prices = [float(price) if price != "" else 0 for price in prices]
        average = sum(prices) / len(prices)
        df2.at[index,'Option Premium Amount'] = average
    df2 = df2.reset_index()
    df2.pop(df2.columns[0])
    # save filtered to csv
    df2.to_csv(userDir + "\\" + yest + "_ICE_Data_Cleaned.csv", header = True, index = False, sep=',')

    # save to individual df for later, options & swaps --> later will be refiltered to the 5 types
    df_option = df2[(df2["Product Name"].str.contains("option", case = False, na = False)) | (df2["Product Name"].str.contains("exotic", case = False, na = False)) \
                    | (df2["Strike Price"] != 0)]
    df_option = df_option.drop(columns="Price").reset_index() # get rid of unnecessary stuff and reset index
    df_option.pop(df_option.columns[0])
    df_swap = df2[(df2["Product Name"].str.contains("swap", case = False, na = False)) | (df2["Strike Price"] == 0)]
    df_swap = df_swap.drop(columns="Strike Price").drop(columns="Total Call Amount").drop(columns="Total Put Amount").drop(columns="Option Premium Amount").reset_index()
    df_swap.pop(df_swap.columns[0])
 
    return df_swap, df_option

def ice_HH(ice_swap, ice_option):
    ## ice nymex option
    ice_nymex_option = ice_option[(ice_option["Underlier ID Leg 1"].str.contains("NY", case = False, na = False)) | (ice_option["Product Name"].str.contains("Hub", case = False, na = False)) ]
    
    return ice_nymex_option

# main method
if __name__ == "__main__":
    dtcc_swap, dtcc_option = download_dtcc()
    ice_swap, ice_option = download_ice()
    ice_nymex_option = ice_HH(ice_swap, ice_option)

############################################################################
### simple script to pull daily forecast data from wsi to be emailed to natural gas traders (dane c, tom w, mike d, mike c)
### uses wsi api (tom w login) to request 6-10, 11-15 forecast commentary and degree day (gas h or pop c based on season) tables (wsi, gfs ens, eur ens, gfs op)
### stores forecast commentary as string, manually convert to html. DD tables stored in dataframe and converted to html
### dataframes are transposed and cleaned to standardize output to show run, actual, normal, diff (24hr, day to day, and/or 12hr) changes
### use local outlook app to send emails, done with win32
### this version takes into account shoulder season (1/1 - 3/14 & 10/16 - 11/14); code could be cleaned up but it works as is - should just make html compilation and email a function
### also add combined chart of 1-15forecast
### im being lazy right now, but to optimize, should change all pd.dataframe.appends to .concat(), df to html and email should be functions, and should have one function based off season
### (cont.) instead of seperating winter functions and summer functions
### emails with different method

import requests
from datetime import date
import io
import pandas as pd
import datetime
from datetime import date
import win32com.client as win32
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText

http_proxy = 'http://tfang03:$641FerridayCourt@sccswg.bmogc.net:8080'  # line to be changed for someone elses login
proxies={"http":http_proxy,"https":http_proxy}

def swap_rows(df, row1, row2):
    # function to swap rows --> used to swap normal under run and then reposition everything else
    df.iloc[row1], df.iloc[row2] =  df.iloc[row2].copy(), df.iloc[row1].copy()
    return df

def filterDF(df, bool, summer):
    # function to get rid of useless columns from data frame to standardize all of them
    # df.columns = df.iloc[0]
    # get rid of top line junk for header
    summer = summer
    new_header = df.iloc[0]
    df = df[1:]
    df.columns = new_header
    # delimiting and creating expanded dataframes
    if bool == True and summer:
        # Eur model winter
        new_df = df["site_id,model,init_time,period,period_start,period_end,population_cdd,population_cdd_dfn,population_cdd_6hr_difference,population_cdd_12hr_difference,population_cdd_18hr_difference,population_cdd_24hr_difference,population_cdd_30hr_difference,population_cdd_36hr_difference,population_cdd_normal\r\n"].str.split(",", expand =True)
        new_df.pop(new_df.columns[13])
    elif bool == True and summer == False:
        # Eur model winter
        new_df = df["site_id,model,init_time,period,period_start,period_end,gas_hdd,gas_hdd_dfn,gas_hdd_6hr_difference,gas_hdd_12hr_difference,gas_hdd_18hr_difference,gas_hdd_24hr_difference,gas_hdd_30hr_difference,gas_hdd_36hr_difference,gas_hdd_normal\r\n"].str.split(",", expand =True)
        new_df.pop(new_df.columns[13])
    elif bool == False and summer:
        # gfs model summer
        new_df = df["site_id,model,init_time,period,period_start,period_end,population_cdd,population_cdd_dfn,population_cdd_6hr_difference,population_cdd_12hr_difference,population_cdd_18hr_difference,population_cdd_24hr_difference,population_cdd_30hr_difference,population_cdd_normal\r\n"].str.split(",", expand =True)
    elif bool == False and summer == False:
        # gfs model winter
        new_df = df["site_id,model,init_time,period,period_start,period_end,gas_hdd,gas_hdd_dfn,gas_hdd_6hr_difference,gas_hdd_12hr_difference,gas_hdd_18hr_difference,gas_hdd_24hr_difference,gas_hdd_30hr_difference,gas_hdd_normal\r\n"].str.split(",", expand =True)

    # delete unused last col
    new_df.pop(new_df.columns[-1])
    # set column names for new df
    if summer:
        new_df.columns = ["site_id","model","init_time","period","period_start","period_end","population_cdd","population_cdd_dfn","population_cdd_6hr_difference","population_cdd_12hr_difference","population_cdd_18hr_difference","population_cdd_24hr_difference","population_cdd_30hr_difference","population_cdd_normal"]
    else:
        new_df.columns = ["site_id","model","init_time","period","period_start","period_end","gas_hdd","gas_hdd_dfn","gas_hdd_6hr_difference","gas_hdd_12hr_difference","gas_hdd_18hr_difference","gas_hdd_24hr_difference","gas_hdd_30hr_difference","gas_hdd_normal"]

    return new_df

def email_dataframes(df, summer):
    # get the dataframes for the email
    summer = summer
    holder = str(date.today().strftime("%m/%d/%Y")).replace("/0","/")
    if holder[0] == "0":
        holder = holder[1:]
    if summer:
        df_email = pd.DataFrame(columns=["site_id","model","init_time","period","population_cdd","population_cdd_dfn","population_cdd_12hr_difference","population_cdd_24hr_difference","population_cdd_normal"])
        df_holder = pd.DataFrame(columns=["site_id","model","init_time","period","population_cdd","population_cdd_dfn","population_cdd_12hr_difference","population_cdd_24hr_difference","population_cdd_normal"])
    else: 
        df_email = pd.DataFrame(columns=["site_id","model","init_time","period","gas_hdd","gas_hdd_dfn","gas_hdd_12hr_difference","gas_hdd_24hr_difference","gas_hdd_normal"])
        df_holder = pd.DataFrame(columns=["site_id","model","init_time","period","gas_hdd","gas_hdd_dfn","gas_hdd_12hr_difference","gas_hdd_24hr_difference","gas_hdd_normal"])
    # iterate through column init time of merged df; if is today run, save the row to new df df_email
    for index,value in df["init_time"].iteritems():
        if str(value[:value.find(" ")]) == holder:
            copy = df_merged.loc[index]
            df_holder = df_holder.append(copy)
        df_holder = df_holder.reset_index()
        df_holder.pop(df_holder.columns[0])
    for index2,value2 in df_holder['period'].iteritems():
        if str(value2[:3]) != "EIA":
            copy2 = df_holder.loc[index2]
            df_email = df_email.append(copy2)
    df_email = df_email.reset_index()
    df_email.pop(df_email.columns[0])
    if summer:
        gfsop_email = pd.DataFrame(columns=["site_id","model","init_time","period","population_cdd","population_cdd_dfn","population_cdd_12hr_difference","population_cdd_24hr_difference","population_cdd_normal"])
        gfsen_email = pd.DataFrame(columns=["site_id","model","init_time","period","population_cdd","population_cdd_dfn","population_cdd_12hr_difference","population_cdd_24hr_difference","population_cdd_normal"])
        euren_email = pd.DataFrame(columns=["site_id","model","init_time","period","population_cdd","population_cdd_dfn","population_cdd_12hr_difference","population_cdd_24hr_difference","population_cdd_normal"])
    else:
        gfsop_email = pd.DataFrame(columns=["site_id","model","init_time","period","gas_hdd","gas_hdd_dfn","gas_hdd_12hr_difference","gas_hdd_24hr_difference","gas_hdd_normal"])
        gfsen_email = pd.DataFrame(columns=["site_id","model","init_time","period","gas_hdd","gas_hdd_dfn","gas_hdd_12hr_difference","gas_hdd_24hr_difference","gas_hdd_normal"])
        euren_email = pd.DataFrame(columns=["site_id","model","init_time","period","gas_hdd","gas_hdd_dfn","gas_hdd_12hr_difference","gas_hdd_24hr_difference","gas_hdd_normal"])
    df_email['init_time'] = "0z run"
    for opindex, opvalue in df_email['model'].iteritems():
        if opvalue == "GFS_OP":
            copy3 = df_email.loc[opindex]
            gfsop_email = gfsop_email.append(copy3)
        if opvalue == "GFS_ENS":
            copy3 = df_email.loc[opindex]
            gfsen_email = gfsen_email.append(copy3)
        if opvalue == "ECMWF_ENS":
            copy3 = df_email.loc[opindex]
            euren_email = euren_email.append(copy3)
    gfsop_email = gfsop_email.reset_index()
    gfsop_email.pop(gfsop_email.columns[0])

    gfsen_email = gfsen_email.reset_index()
    gfsen_email.pop(gfsen_email.columns[0])
    
    euren_email = euren_email.reset_index()
    euren_email.pop(euren_email.columns[0])
    
    # accomadting for row swap, row 8 became row 4, and every other row shifted down
    if summer:
        gfsop_email.columns = ['Site','Model','Run','Period','CDD Normal',"CDD",'CDD DFN','CDD 12hr Diff',"CDD 24hr Diff"]
        gfsen_email.columns = ['Site','Model','Run','Period','CDD Normal',"CDD",'CDD DFN','CDD 12hr Diff',"CDD 24hr Diff"]
        euren_email.columns = ['Site','Model','Run','Period','CDD Normal',"CDD",'CDD DFN','CDD 12hr Diff',"CDD 24hr Diff"]
    else:
        gfsop_email.columns = ['Site','Model','Run','Period','HDD Normal',"HDD",'HDD DFN','HDD 12hr Diff',"HDD 24hr Diff"]
        gfsen_email.columns = ['Site','Model','Run','Period','HDD Normal',"HDD",'HDD DFN','HDD 12hr Diff',"HDD 24hr Diff"]
        euren_email.columns = ['Site','Model','Run','Period','HDD Normal',"HDD",'HDD DFN','HDD 12hr Diff',"HDD 24hr Diff"]

    gfsop_email = gfsop_email.transpose()
    gfsen_email = gfsen_email.transpose()
    euren_email = euren_email.transpose()

    gfsop_email = swap_rows(gfsop_email, 4, 8)
    gfsop_email = swap_rows(gfsop_email, 8, 7)
    gfsop_email = swap_rows(gfsop_email, 7, 6)
    gfsop_email = swap_rows(gfsop_email, 6, 5)

    gfsen_email = swap_rows(gfsen_email, 4, 8)
    gfsen_email = swap_rows(gfsen_email, 8, 7)
    gfsen_email = swap_rows(gfsen_email, 7, 6)
    gfsen_email = swap_rows(gfsen_email, 6, 5)

    euren_email = swap_rows(euren_email, 4, 8)
    euren_email = swap_rows(euren_email, 8, 7)
    euren_email = swap_rows(euren_email, 7, 6)
    euren_email = swap_rows(euren_email, 6, 5)

    return gfsop_email, gfsen_email, euren_email

def model_dfs(summer):
    summer = summer
    headers = {
        'Accept': "application/json",
        'Accept': 'application/csv'
    }

    # login info
    wsiUser = "bmo"
    wsiEmail = "tom.widdowson@bmo.com"
    wsiPassword = "snowywinter2022"

    # Forecast Commentary
    region = "NA"
    sixten = "6-10"
    elevfif = "11-15"
    sixtenURL = "http://www.wsitrader.com/Services/CSVDownloadService.svc/GetForecastDiscussions?Account="+wsiUser+"&profile="+wsiEmail+"&password="+wsiPassword+"&ForecastRange="+sixten+"&Region=" + region
    elevfifURL = "http://www.wsitrader.com/Services/CSVDownloadService.svc/GetForecastDiscussions?Account="+wsiUser+"&profile="+wsiEmail+"&password="+wsiPassword+"&ForecastRange="+elevfif+"&Region=" + region

    # Degree Day Forecast Models
    gfsOPModel = "GFS_OP"
    gfsENModel = "GFS_ENS"
    eurENModel = "ECMWF_ENS"
    stations = "Stations[]=CONUS"
    if summer:
        dataTypes = "datatypes[]=population_cdd"
    else:   
        dataTypes = "datatypes[]=gas_hdd"
    gfsOPURL = "http://www.wsitrader.com/Services/CSVDownloadService.svc/GetWeightedDegreeDayForecast?Account="+wsiUser+"&Profile="+wsiEmail+"&Password="+wsiPassword+"&forecasttype=Period&Model="+gfsOPModel+"&BiasCorrected=true&"+stations+"&"+dataTypes+"&Region=NA"
    gfsENURL = "http://www.wsitrader.com/Services/CSVDownloadService.svc/GetWeightedDegreeDayForecast?Account="+wsiUser+"&Profile="+wsiEmail+"&Password="+wsiPassword+"&forecasttype=Period&Model="+gfsENModel+"&BiasCorrected=true&"+stations+"&"+dataTypes+"&Region=NA"
    eurENURL = "http://www.wsitrader.com/Services/CSVDownloadService.svc/GetWeightedDegreeDayForecast?Account="+wsiUser+"&Profile="+wsiEmail+"&Password="+wsiPassword+"&forecasttype=Period&Model="+eurENModel+"&BiasCorrected=true&"+stations+"&"+dataTypes+"&Region=NA"

    sixtenResponse = requests.get(sixtenURL,headers=headers,proxies=proxies,verify=False).text
    elevfifResponse = requests.get(elevfifURL,headers=headers,proxies=proxies,verify=False).text
    gfsOPResponse = io.StringIO(requests.get(gfsOPURL,headers=headers,proxies=proxies,verify=False).text)
    gfsENResponse = io.StringIO(requests.get(gfsENURL,headers=headers,proxies=proxies,verify=False).text)
    eurENResponse = io.StringIO(requests.get(eurENURL,headers=headers,proxies=proxies,verify=False).text)

    dfGfsOp = pd.DataFrame(gfsOPResponse) 
    dfGfsEn = pd.DataFrame(gfsENResponse)
    dfEurEn = pd.DataFrame(eurENResponse)
    # drop first row
    dfGfsOp.drop(index=dfGfsOp.index[0],axis=0,inplace = True)
    dfGfsEn.drop(index=dfGfsEn.index[0],axis=0,inplace = True)
    dfEurEn.drop(index=dfEurEn.index[0],axis=0,inplace = True)

    dfGfsOp = filterDF(dfGfsOp, False, summer)
    dfGfsEn = filterDF(dfGfsEn, False, summer)
    dfEurEn = filterDF(dfEurEn, True, summer)

    # merge dataframes 
    df_merged = pd.concat([dfGfsOp,dfGfsEn,dfEurEn],ignore_index=True)
    # pop unneeded cols
    if summer:
        df_merged = df_merged.drop(["population_cdd_6hr_difference","population_cdd_18hr_difference","population_cdd_30hr_difference","period_start","period_end"], axis = 1)
    else: 
        df_merged = df_merged.drop(["gas_hdd_6hr_difference","gas_hdd_18hr_difference","gas_hdd_30hr_difference","period_start","period_end"], axis = 1)
    # dropping all models except for 0z and 12z run
    df_merged = df_merged[df_merged["init_time"].str.contains("6:00:00 AM") == False]
    df_merged = df_merged[df_merged["init_time"].str.contains("6:00:00 PM") == False]
    df_merged = df_merged[df_merged["init_time"].str.contains("12:00:00 PM") == False]
    df_merged = df_merged[df_merged["period"].str.contains("Obs Month to Date") == False]
    # reset df index and drop first col bc reset index adds col; prev kept index from old dfs so everything was fucked up
    df_merged = df_merged.reset_index()
    df_merged.pop(df_merged.columns[0])
    return df_merged, sixtenResponse, elevfifResponse

def wsi_model(summer):
    summer = summer
    headers = {
        'Accept': "application/json",
        'Accept': 'application/csv'
    }

    # login info
    wsiUser = "bmo"
    wsiEmail = "tom.widdowson@bmo.com"
    wsiPassword = "snowywinter2022"

    # Degree Day Forecast Models
    wsiModel = "WSI"
    stations = "Stations[]=CONUS"
    if summer:
        dataTypes = "datatypes[]=population_cdd"
    else:
        dataTypes = "datatypes[]=gas_hdd"

    wsiURL = "http://www.wsitrader.com/Services/CSVDownloadService.svc/GetWeightedDegreeDayForecast?Account="+wsiUser+"&Profile="+wsiEmail+"&Password="+wsiPassword+"&forecasttype=Period&Model="+wsiModel+"&BiasCorrected=true&"+stations+"&"+dataTypes+"&Region=NA"

    wsiReponse = io.StringIO(requests.get(wsiURL, headers= headers,proxies=proxies, verify=False).text)
    dfWSI = pd.DataFrame(wsiReponse)
    
    ### df formatting
    # drop first row
    dfWSI.drop(index=dfWSI.index[0],axis=0,inplace = True)
    # top header adjustment
    new_header = dfWSI.iloc[0]
    dfWSI = dfWSI[1:]
    dfWSI.columns = new_header
    if summer:
        # for summer give pop cdd
        # delimit df and expand based off header names
        new_df = dfWSI["site_id,init_time,period,period_start,period_end,population_cdd,population_cdd_normal,population_cdd_difference,population_cdd_dfn\r\n"].str.split(",", expand = True)
        # set column names for new df
        new_df.columns = ["site_id","init_time","period","period_start","period_end","population_cdd","population_cdd_normal","population_cdd_difference","population_cdd_dfn"]
    else:
        # for winter give gas hdd
        # delimit df and expand based off header names
        new_df = dfWSI["site_id,init_time,period,period_start,period_end,gas_hdd,gas_hdd_normal,gas_hdd_difference,gas_hdd_dfn\r\n"].str.split(",", expand = True)
        # set column names for new df
        new_df.columns = ["site_id","init_time","period","period_start","period_end","gas_hdd","gas_hdd_normal","gas_hdd_difference","gas_hdd_dfn"]

    # delte unused cols
    new_df = new_df.drop('period_start', axis = 1)
    new_df = new_df.drop('period_end', axis = 1)
    # back to original var, iterate through and get rid of EIA data, tranpose to uniform format
    dfWSI = pd.DataFrame()
    for index,value in new_df['period'].iteritems():
        if str(value[:3]) != "EIA":
            copy = new_df.loc[index]
            dfWSI = dfWSI.append(copy)
    dfWSI['init_time'] = "WSI Run"
    dfWSI = dfWSI.reset_index()
    dfWSI.pop(dfWSI.columns[0])
    if summer:
        # summer pop cdd
        # rename cols, allocating for row swaps
        dfWSI.columns = ['Site','Model','Period','CDD Normal','CDD','CDD DFN',"CDD Diff"]
    else:
        # winter gas cdd
        # rename cols, allocating for row swaps
        dfWSI.columns = ['Site','Model','Period','HDD Normal','HDD','HDD DFN',"HDD Diff"]
        
    dfWSI = dfWSI.transpose()
    # swap cdd & cdd normal
    dfWSI = swap_rows(dfWSI,3,4)
    # swap diff and dfn
    dfWSI = swap_rows(dfWSI,5,6)
    dfWSI.drop(dfWSI.columns[len(dfWSI.columns)-1], axis=1, inplace=True)

    return dfWSI

def color_cells_summer(val):
    val = float(val)
    if pd.notnull(val) and val != 0:
        # positive cdd
        if 2 >= val > 0:
            return 'background-color: #FFD5A8;' # lightest red 
        elif 4 > val >= 2:
            return 'background-color: #FFB25F;' 
        elif 6 > val >= 4:
            return 'background-color: #FF694B;' 
        elif 8 > val >= 6:
            return 'background-color: #FF2A00;'
        elif 10 > val >= 8:
            return 'background-color: #DC2400;' 
        elif val >= 10:
            return 'background-color: #9B0000;' 
        # negative cdd
        elif -2 <= val < 0:
            return 'background-color: #DCF1FF;' # lightest blue
        elif -4 <= val < -2:
            return 'background-color: #9BD7FF;'
        elif -6 <= val < -4:
            return 'background-color: #50B9FF;'
        elif -8 <= val < -6:
            return 'background-color: #13A1FF;'        
        elif -10 <= val < -8:
            return 'background-color: #0088E1;'        
        elif val < -10:
            return 'background-color: #003DA9;' # darkest blue

def color_cells_winter(val):
    val = float(val)
    if pd.notnull(val) and val != 0:
        # positive cdd
        if 2 >= val > 0:
            return 'background-color: #DCF1FF;' # lightest blue
        elif 4 > val >= 2:
            return 'background-color: #9BD7FF;' 
        elif 6 > val >= 4:
            return 'background-color: #50B9FF;' 
        elif 8 > val >= 6:
            return 'background-color: #13A1FF;'
        elif 10 > val >= 8:
            return 'background-color: #0088E1;' 
        elif val >= 10:
            return 'background-color: #003DA9;'# dark blue
        # negative cdd
        elif -2 <= val < 0:
            return 'background-color: #FFD5A8;' # lightest red
        elif -4 <= val < -2:
            return 'background-color: #FFB25F;'
        elif -6 <= val < -4:
            return 'background-color: #FF694B;'
        elif -8 <= val < -6:
            return 'background-color: #FF2A00;'        
        elif -10 <= val < -8:
            return 'background-color: #DC2400;'        
        elif val < -10:
            return 'background-color: #9B0000;' # darkest red

def only_115(hold1,hold2,hold3):
    # col_hold = []
    # if "Period" in hold1.index and hold1.loc["Period"].str.contains("1-15 Day").any():
    #     col_hold.extend(hold1.columns[hold1.loc["Period"] == "1-15 Day"].tolist())
    # if "Period" in hold2.index and hold2.loc["Period"].str.contains("11-15 Day").any():
    #     col_hold.extend(hold2.columns[hold2.loc["Period"] == "1-15 Day"].tolist())
    # if "Period" in hold3.index and hold3.loc["Period"].str.contains("11-15 Day").any():
    #     col_hold.extend(hold3.columns[hold3.loc["Period"] == "1-15 Day"].tolist())
    # df = pd.concat([hold1[col_hold],hold2[col_hold],hold3[col_hold]], axis = 1)
    df = pd.concat([hold1[3],hold2[3],hold3[3]], axis = 1)
    return df

today = datetime.datetime.now()
# today = datetime.datetime(2023,10,16)

# evaluate season for email, if shoulder send both cdd and hdd; should put the stuff into function for readability/efficiency since it all does the same thing but oh well
if datetime.datetime(today.year,4,15) <= today <= datetime.datetime(today.year,10,15):
    ### SUMMER
    season = "Summer"
    summer = True
    df_merged, sixtenResponse, elevfifResponse = model_dfs(summer)
    dfWSI = wsi_model(summer)
    gfsop_email, gfsen_email, euren_email = email_dataframes(df_merged, summer)

    # combo of 1-15 only
    combo = only_115(gfsen_email,euren_email,gfsop_email)
    combo = combo.T.reset_index(drop=True).T
    combo = pd.concat([dfWSI[3],combo], axis = 1)
    combo = swap_rows(combo,7,2)
    combo = swap_rows(combo,7,6)
    combo = swap_rows(combo,6,5)
    combo = swap_rows(combo,5,4)
    combo = swap_rows(combo,4,3)
    combo = swap_rows(combo,3,2)
    combo = swap_rows(combo,2,3)
    combo.index = ["Site","Model","Run","Period","CDD Normal","CDD","CDD DFN","CDD Diff","CDD 12hr Diff","CDD 24hr Diff"]
    combo = combo.T.reset_index(drop=True).T
    combo = combo.style.applymap(color_cells_summer,subset=pd.IndexSlice["CDD DFN":, combo.columns[0:]])
    combo = combo.to_html(index = True, header = False).replace("nan","")
    combo = combo[:combo.index("table id")] + "table border = ""1 """ + combo[combo.index("table id"):]
    combo = combo[:combo.index("<thead>")] + combo[combo.index("</thead>"):]

    # add heatmap, convert to html, add borders back, delete headers bc style.applymap overrides header = false
    wsi_email = dfWSI.style.applymap(color_cells_summer,subset=pd.IndexSlice["CDD DFN":, dfWSI.columns[0:]])
    wsi_email = wsi_email.to_html(index = True, header = False)
    wsi_email = wsi_email[:wsi_email.index("table id")] + "table border = ""1 """ + wsi_email[wsi_email.index("table id"):]
    wsi_email = wsi_email[:wsi_email.index("<thead>")] + wsi_email[wsi_email.index("</thead>"):]

    gfsen_email = gfsen_email.style.applymap(color_cells_summer,subset=pd.IndexSlice["CDD DFN":, gfsen_email.columns[0:]])
    gfsen_email = gfsen_email.to_html(index = True, header = False)
    gfsen_email = gfsen_email[:gfsen_email.index("table id")] + "table border = ""1 """ + gfsen_email[gfsen_email.index("table id"):]
    gfsen_email = gfsen_email[:gfsen_email.index("<thead>")] + gfsen_email[gfsen_email.index("</thead>"):]

    gfsop_email = gfsop_email.style.applymap(color_cells_summer,subset=pd.IndexSlice["CDD DFN":, gfsop_email.columns[0:]])
    gfsop_email = gfsop_email.to_html(index = True, header = False)
    gfsop_email = gfsop_email[:gfsop_email.index("table id")] + "table border = ""1 """ + gfsop_email[gfsop_email.index("table id"):]
    gfsop_email = gfsop_email[:gfsop_email.index("<thead>")] + gfsop_email[gfsop_email.index("</thead>"):]

    euren_email = euren_email.style.applymap(color_cells_summer,subset=pd.IndexSlice["CDD DFN":, euren_email.columns[0:]])
    euren_email = euren_email.to_html(index = True, header = False)
    euren_email = euren_email[:euren_email.index("table id")] + "table border = ""1 """ + euren_email[euren_email.index("table id"):]
    euren_email = euren_email[:euren_email.index("<thead>")] + euren_email[euren_email.index("</thead>"):]
    
    charts_email = wsi_email + "<br>" + gfsen_email + "<br>" + euren_email + "<br>" + gfsop_email + "<br>"

    greeting = "<BODY> Good morning,<br><br>From WSITrader, today's WSI, GFS ENS, EUR ENS, and GFS OP Degree Day runs are:<br><br> </BODY>"

    forecasts = \
    "<BODY>" + sixtenResponse + "<br><br>" + elevfifResponse + "<br><br> \
    </BODY>"
    today = str(date.today().strftime("%m-%d-%y"))

    salutation = \
    "<BODY>Best,<br>Theo<br><br></BODY>"

    outlook = win32.Dispatch('outlook.application')
    mail = outlook.CreateItem(0)
    # mail.To = "dane.carillo@bmo.com; mike.cowan@bmo.com; tom.widdowson@bmo.com; michael.dannunzio@bmo.com"
    # mail.To = "theo.fang@bmo.com"
    mail.Subject = "WSI Summary " + today
    mail.HTMLBody = greeting + combo + "<br>" + forecasts + charts_email + salutation
    # mail.Send()

    print("Email successfully sent.")
    body = greeting + combo + "<br>" + forecasts + charts_email + salutation

elif datetime.datetime(today.year,1,1) <= today <= datetime.datetime(today.year,3,15) or datetime.datetime(today.year,11,15) <= today <= datetime.datetime(today.year,12,31):
    ### WINTER
    season = "Winter"
    summer = False
    dfWSI = wsi_model(summer)
    df_merged, sixtenResponse, elevfifResponse = model_dfs(summer)
    gfsop_email, gfsen_email, euren_email = email_dataframes(df_merged, summer)

    # combo of 1-15 only
    combo = only_115(gfsen_email,euren_email,gfsop_email)
    combo = combo.T.reset_index(drop=True).T
    combo = pd.concat([dfWSI[3],combo], axis = 1)
    combo = swap_rows(combo,7,2)
    combo = swap_rows(combo,7,6)
    combo = swap_rows(combo,6,5)
    combo = swap_rows(combo,5,4)
    combo = swap_rows(combo,4,3)
    combo = swap_rows(combo,3,2)
    combo = swap_rows(combo,2,3)
    combo.index = ["Site","Model","Run","Period","HDD Normal","HDD","HDD DFN","HDD Diff","HDD 12hr Diff","HDD 24hr Diff"]
    combo = combo.T.reset_index(drop=True).T
    combo = combo.style.applymap(color_cells_winter,subset=pd.IndexSlice["HDD DFN":, combo.columns[0:]])
    combo = combo.to_html(index = True, header = False).replace("nan","")
    combo = combo[:combo.index("table id")] + "table border = ""1 """ + combo[combo.index("table id"):]
    combo = combo[:combo.index("<thead>")] + combo[combo.index("</thead>"):]

    # add heatmap, convert to html, add borders back, delete headers bc style.applymap overrides header = false
    wsi_email = dfWSI.style.applymap(color_cells_winter,subset=pd.IndexSlice["HDD DFN":, dfWSI.columns[0:]])
    wsi_email = wsi_email.to_html(index = True, header = False)
    wsi_email = wsi_email[:wsi_email.index("table id")] + "table border = ""1 """ + wsi_email[wsi_email.index("table id"):]
    wsi_email = wsi_email[:wsi_email.index("<thead>")] + wsi_email[wsi_email.index("</thead>"):]

    gfsen_email = gfsen_email.style.applymap(color_cells_winter,subset=pd.IndexSlice["HDD DFN":, gfsen_email.columns[0:]])
    gfsen_email = gfsen_email.to_html(index = True, header = False)
    gfsen_email = gfsen_email[:gfsen_email.index("table id")] + "table border = ""1 """ + gfsen_email[gfsen_email.index("table id"):]
    gfsen_email = gfsen_email[:gfsen_email.index("<thead>")] + gfsen_email[gfsen_email.index("</thead>"):]

    gfsop_email = gfsop_email.style.applymap(color_cells_winter,subset=pd.IndexSlice["HDD DFN":, gfsop_email.columns[0:]])
    gfsop_email = gfsop_email.to_html(index = True, header = False)
    gfsop_email = gfsop_email[:gfsop_email.index("table id")] + "table border = ""1 """ + gfsop_email[gfsop_email.index("table id"):]
    gfsop_email = gfsop_email[:gfsop_email.index("<thead>")] + gfsop_email[gfsop_email.index("</thead>"):]

    euren_email = euren_email.style.applymap(color_cells_winter,subset=pd.IndexSlice["HDD DFN":, euren_email.columns[0:]])
    euren_email = euren_email.to_html(index = True, header = False)
    euren_email = euren_email[:euren_email.index("table id")] + "table border = ""1 """ + euren_email[euren_email.index("table id"):]
    euren_email = euren_email[:euren_email.index("<thead>")] + euren_email[euren_email.index("</thead>"):]

    charts_email = wsi_email + "<br>" + gfsen_email + "<br>" + euren_email + "<br>" + gfsop_email + "<br>"

    greeting = "<BODY> Good morning,<br><br>From WSITrader, today's WSI, GFS ENS, EUR ENS, and GFS OP Degree Day runs are:<br><br> </BODY>"

    forecasts = \
    "<BODY>" + sixtenResponse + "<br><br>" + elevfifResponse + "<br><br> \
    </BODY>"
    today = str(date.today().strftime("%m-%d-%y"))

    salutation = \
    "<BODY>Best,<br>Theo<br><br></BODY>"

    # outlook = win32.Dispatch('outlook.application')
    # mail = outlook.CreateItem(0)
    # mail.To = "dane.carillo@bmo.com; mike.cowan@bmo.com; tom.widdowson@bmo.com; michael.dannunzio@bmo.com"
    # # mail.To = "theo.fang@bmo.com"
    # mail.Subject = "WSI Summary " + today
    # mail.HTMLBody = greeting + combo + "<br>" + forecasts + charts_email + salutation
    # mail.Send()

    # print("Email successfully sent.")
    body = greeting + combo + "<br>" + forecasts + charts_email + salutation

else:
    ### SHOULDER
    # summer first
    summer = True
    dfWSI_summer = wsi_model(summer)
    df_merged, sixtenResponse_summer, elevfifResponse_summer = model_dfs(summer)
    gfsop_email_summer, gfsen_email_summer, euren_email_summer = email_dataframes(df_merged, summer)

    # combo of 1-15 only
    # summer
    combo_summer = only_115(gfsen_email_summer,euren_email_summer,gfsop_email_summer)
    combo_summer = combo_summer.T.reset_index(drop=True).T
    combo_summer = pd.concat([dfWSI_summer[3],combo_summer], axis = 1)
    combo_summer = swap_rows(combo_summer,7,2)
    combo_summer = swap_rows(combo_summer,7,6)
    combo_summer = swap_rows(combo_summer,6,5)
    combo_summer = swap_rows(combo_summer,5,4)
    combo_summer = swap_rows(combo_summer,4,3)
    combo_summer = swap_rows(combo_summer,3,2)
    combo_summer = swap_rows(combo_summer,2,3)
    combo_summer.index = ["Site","Model","Run","Period","CDD Normal","CDD","CDD DFN","CDD Diff","CDD 12hr Diff","CDD 24hr Diff"]
    combo_summer = combo_summer.T.reset_index(drop=True).T
    combo_summer = combo_summer.style.applymap(color_cells_summer,subset=pd.IndexSlice["CDD DFN":, combo_summer.columns[0:]])
    combo_summer = combo_summer.to_html(index = True, header = False).replace("nan","")
    combo_summer = combo_summer[:combo_summer.index("table id")] + "table border = ""1 """ + combo_summer[combo_summer.index("table id"):]
    combo_summer = combo_summer[:combo_summer.index("<thead>")] + combo_summer[combo_summer.index("</thead>"):]

    # add heatmap, convert to html, add borders back, delete headers bc style.applymap overrides header = false
    wsi_email_summer = dfWSI_summer.style.applymap(color_cells_summer,subset=pd.IndexSlice["CDD DFN":, dfWSI_summer.columns[0:]])
    wsi_email_summer = wsi_email_summer.to_html(index = True, header = False)
    wsi_email_summer = wsi_email_summer[:wsi_email_summer.index("table id")] + "table border = ""1 """ + wsi_email_summer[wsi_email_summer.index("table id"):]
    wsi_email_summer = wsi_email_summer[:wsi_email_summer.index("<thead>")] + wsi_email_summer[wsi_email_summer.index("</thead>"):]

    gfsen_email_summer = gfsen_email_summer.style.applymap(color_cells_summer,subset=pd.IndexSlice["CDD DFN":, gfsen_email_summer.columns[0:]])
    gfsen_email_summer = gfsen_email_summer.to_html(index = True, header = False)
    gfsen_email_summer = gfsen_email_summer[:gfsen_email_summer.index("table id")] + "table border = ""1 """ + gfsen_email_summer[gfsen_email_summer.index("table id"):]
    gfsen_email_summer = gfsen_email_summer[:gfsen_email_summer.index("<thead>")] + gfsen_email_summer[gfsen_email_summer.index("</thead>"):]

    gfsop_email_summer = gfsop_email_summer.style.applymap(color_cells_summer,subset=pd.IndexSlice["CDD DFN":, gfsop_email_summer.columns[0:]])
    gfsop_email_summer = gfsop_email_summer.to_html(index = True, header = False)
    gfsop_email_summer = gfsop_email_summer[:gfsop_email_summer.index("table id")] + "table border = ""1 """ + gfsop_email_summer[gfsop_email_summer.index("table id"):]
    gfsop_email_summer = gfsop_email_summer[:gfsop_email_summer.index("<thead>")] + gfsop_email_summer[gfsop_email_summer.index("</thead>"):]

    euren_email_summer = euren_email_summer.style.applymap(color_cells_summer,subset=pd.IndexSlice["CDD DFN":, euren_email_summer.columns[0:]])
    euren_email_summer = euren_email_summer.to_html(index = True, header = False)
    euren_email_summer = euren_email_summer[:euren_email_summer.index("table id")] + "table border = ""1 """ + euren_email_summer[euren_email_summer.index("table id"):]
    euren_email_summer = euren_email_summer[:euren_email_summer.index("<thead>")] + euren_email_summer[euren_email_summer.index("</thead>"):]
    # winter
    summer = False
    dfWSI_winter = wsi_model(summer)
    df_merged, sixtenResponse_winter, elevfifResponse_winter = model_dfs(summer)
    gfsop_email_winter, gfsen_email_winter, euren_email_winter = email_dataframes(df_merged, summer)

    # winter
    combo_winter = only_115(gfsen_email_winter,euren_email_winter,gfsop_email_winter)
    combo_winter = combo_winter.T.reset_index(drop=True).T
    combo_winter = pd.concat([dfWSI_winter[3],combo_winter], axis = 1)
    combo_winter = swap_rows(combo_winter,7,2)
    combo_winter = swap_rows(combo_winter,7,6)
    combo_winter = swap_rows(combo_winter,6,5)
    combo_winter = swap_rows(combo_winter,5,4)
    combo_winter = swap_rows(combo_winter,4,3)
    combo_winter = swap_rows(combo_winter,3,2)
    combo_winter = swap_rows(combo_winter,2,3)
    combo_winter.index = ["Site","Model","Run","Period","HDD Normal","HDD","HDD DFN","HDD Diff","HDD 12hr Diff","HDD 24hr Diff"]
    combo_winter = combo_winter.T.reset_index(drop=True).T
    combo_winter = combo_winter.style.applymap(color_cells_winter,subset=pd.IndexSlice["HDD DFN":, combo_winter.columns[0:]])
    combo_winter = combo_winter.to_html(index = True, header = False).replace("nan","")
    combo_winter = combo_winter[:combo_winter.index("table id")] + "table border = ""1 """ + combo_winter[combo_winter.index("table id"):]
    combo_winter = combo_winter[:combo_winter.index("<thead>")] + combo_winter[combo_winter.index("</thead>"):]

    # add heatmap, convert to html, add borders back, delete headers bc style.applymap overrides header = false
    wsi_email_winter = dfWSI_winter.style.applymap(color_cells_winter,subset=pd.IndexSlice["HDD DFN":, dfWSI_winter.columns[0:]])
    wsi_email_winter = wsi_email_winter.to_html(index = True, header = False)
    wsi_email_winter = wsi_email_winter[:wsi_email_winter.index("table id")] + "table border = ""1 """ + wsi_email_winter[wsi_email_winter.index("table id"):]
    wsi_email_winter = wsi_email_winter[:wsi_email_winter.index("<thead>")] + wsi_email_winter[wsi_email_winter.index("</thead>"):]

    gfsen_email_winter = gfsen_email_winter.style.applymap(color_cells_winter,subset=pd.IndexSlice["HDD DFN":, gfsen_email_winter.columns[0:]])
    gfsen_email_winter = gfsen_email_winter.to_html(index = True, header = False)
    gfsen_email_winter = gfsen_email_winter[:gfsen_email_winter.index("table id")] + "table border = ""1 """ + gfsen_email_winter[gfsen_email_winter.index("table id"):]
    gfsen_email_winter = gfsen_email_winter[:gfsen_email_winter.index("<thead>")] + gfsen_email_winter[gfsen_email_winter.index("</thead>"):]

    gfsop_email_winter = gfsop_email_winter.style.applymap(color_cells_winter,subset=pd.IndexSlice["HDD DFN":, gfsop_email_winter.columns[0:]])
    gfsop_email_winter = gfsop_email_winter.to_html(index = True, header = False)
    gfsop_email_winter = gfsop_email_winter[:gfsop_email_winter.index("table id")] + "table border = ""1 """ + gfsop_email_winter[gfsop_email_winter.index("table id"):]
    gfsop_email_winter = gfsop_email_winter[:gfsop_email_winter.index("<thead>")] + gfsop_email_winter[gfsop_email_winter.index("</thead>"):]

    euren_email_winter = euren_email_winter.style.applymap(color_cells_winter,subset=pd.IndexSlice["HDD DFN":, euren_email_winter.columns[0:]])
    euren_email_winter = euren_email_winter.to_html(index = True, header = False)
    euren_email_winter = euren_email_winter[:euren_email_winter.index("table id")] + "table border = ""1 """ + euren_email_winter[euren_email_winter.index("table id"):]
    euren_email_winter = euren_email_winter[:euren_email_winter.index("<thead>")] + euren_email_winter[euren_email_winter.index("</thead>"):]

    charts_email = wsi_email_summer + "<br>" + wsi_email_winter + "<br>" + gfsen_email_summer + "<br>" + gfsen_email_winter + "<br>" + euren_email_summer + "<br>" + euren_email_winter + "<br>" + gfsop_email_summer + "<br>" + gfsop_email_winter + "<br>"

    greeting = "<BODY> Good morning,<br><br>From WSITrader, today's WSI, GFS ENS, EUR ENS, and GFS OP Degree Day runs are:<br><br> </BODY>"

    forecasts = \
    "<BODY>" + sixtenResponse_summer + "<br><br>" + elevfifResponse_summer + "<br><br> \
    </BODY>"
    today = str(date.today().strftime("%m-%d-%y"))

    salutation = \
    "<BODY>Best,<br>Theo<br><br></BODY>"

    # outlook = win32.Dispatch('outlook.application')
    # mail = outlook.CreateItem(0)
    # mail.To = "dane.carillo@bmo.com; mike.cowan@bmo.com; tom.widdowson@bmo.com; michael.dannunzio@bmo.com"
    # # mail.To = "theo.fang@bmo.com"
    # mail.Subject = "WSI Summary " + today
    # mail.HTMLBody = greeting + combo_summer + "<br>" + combo_winter + "<br>" + forecasts + charts_email + salutation
    # mail.Send()

    # print("Email successfully sent.")
    body = greeting + combo_summer + "<br>" + combo_winter + "<br>" + forecasts + charts_email + salutation

def send_html_email(sender_email, sender_password, recipient_email, subject, html_content):
    # Set up the SMTP server
    smtp_server = "smtp-mail.outlook.com"
    smtp_port = 587  # Change to the appropriate port if needed

    # Create a MIMEText object to hold the HTML content
    msg = MIMEMultipart()
    msg['From'] = sender_email
    msg['To'] = recipient_email
    msg['Subject'] = subject

    # Attach the HTML content to the email
    msg.attach(MIMEText(html_content, 'html'))

    # Start the SMTP session and send the email
    try:
        with smtplib.SMTP(smtp_server, smtp_port) as server:
            server.starttls()
            server.login(sender_email, sender_password)
            server.sendmail(sender_email, recipient_email, msg.as_string())
        print("Email sent successfully")
    except Exception as e:
        print("Error sending email:", str(e))

# send_html_email("theo.fang@bmo.com", "Special01", "theo.fang@bmo.com", "WSI Summary "+ today, body)

